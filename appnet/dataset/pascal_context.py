
import os, cv2, numpy as np, torch
from torch.nn import functional as F
from PIL import Image
from .base import BaseDataset

class Pascal_context(BaseDataset):

    def __init__(self, opt):
        super().__init__(opt)
        ignore_label = 255
        self.class_mapping = {0:ignore_label,
         1:0,
         2:1,
         3:2,
         4:3,
         5:4,
         6:5,
         7:6,
         8:7,
         9:8,
         10:9,
         11:10,
         12:11,
         13:12,
         14:13,
         15:14,
         16:15,
         17:16,
         18:17,
         19:18,
         20:19,
         21:20,
         22:21,
         23:22,
         24:23,
         25:24,
         26:25,
         27:26,
         28:27,
         29:28,
         30:29,
         31:30,
         32:31,
         33:32,
         34:33,
         35:34,
         36:35,
         37:36,
         38:37,
         39:38,
         40:39,
         41:40,
         42:41,
         43:42,
         44:43,
         45:44,
         46:45,
         47:46,
         48:47,
         49:48,
         50:49,
         51:50,
         52:51,
         53:52,
         54:53,
         55:54,
         56:55,
         57:56,
         58:57,
         59:58,
         60:59,
         }
        self.ignore_label = ignore_label
        self.label2color = {0:(120, 120, 120),
         1:(180, 120, 120),
         2:(6, 230, 230),
         3:(80, 50, 50),
         4:(4, 200, 3),
         5:(120, 120, 80),
         6:(140, 140, 140),
         7:(204, 5, 255),
         8:(230, 230, 230),
         9:(4, 250, 7),
         10:(224, 5, 255),
         11:(235, 255, 7),
         12:(150, 5, 61),
         13:(120, 120, 70),
         14:(8, 255, 51),
         15:(255, 6, 82),
         16:(143, 255, 140),
         17:(204, 255, 4),
         18:(255, 51, 7),
         19:(204, 70, 3),
         20:(0, 102, 200),
         21:(61, 230, 250),
         22:(255, 6, 51),
         23:(11, 102, 255),
         24:(255, 7, 71),
         25:(255, 9, 224),
         26:(9, 7, 230),
         27:(220, 220, 220),
         28:(255, 9, 92),
         29:(112, 9, 255),
         30:(8, 255, 214),
         31:(7, 255, 224),
         32:(255, 184, 6),
         33:(10, 255, 71),
         34:(255, 41, 10),
         35:(7, 255, 255),
         36:(224, 255, 8),
         37:(102, 8, 255),
         38:(255, 61, 6),
         39:(255, 194, 7),
         40:(255, 122, 8),
         41:(0, 255, 20),
         42:(255, 8, 41),
         43:(255, 5, 153),
         44:(6, 51, 255),
         45:(235, 12, 255),
         46:(160, 150, 20),
         47:(0, 163, 255),
         48:(140, 140, 140),
         49:(250, 10, 15),
         50:(20, 255, 0),
         51:(31, 255, 0),
         52:(255, 31, 0),
         53:(255, 224, 0),
         54:(153, 255, 0),
         55:(0, 0, 255),
         56:(255, 71, 0),
         57:(0, 235, 255),
         58:(0, 173, 255),
         59:(31, 0, 255),
         }
        self.label_reading_mode = cv2.IMREAD_GRAYSCALE
    def image2class(self, label):
        """Overwrite the parent class to convert grayscale label image"""
        l, w = label.shape[0], label.shape[1]
        classmap = np.zeros(shape=(l, w), dtype=(np.uint8))
        for k, v in self.class_mapping.items():
            classmap[label == k] = v

        return classmap